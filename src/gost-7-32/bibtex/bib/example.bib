@online {rbk, hyphenation = {russian}, author = {Дада Линделл and Маргарита Алехина and Анастасия Скрынникова and Анна Балашова},
    title = {Число дел о мошенничестве рекордно выросло на фоне пандемии. Каким преступлениям поспособствовала самоизоляция},
    date = {08.31.2020},
    url = {https://www.rbc.ru/society/31/08/2020/5f48ea169a79477e21e25d9d},
    label = {РБК},
    urldate = {01.19.2022},
    language = {russian}
}

@article {bai2021,
    title = {Speaker recognition based on deep learning: An overview},
    journal = {Neural Networks},
    volume = {140},
    pages = {65-99},
    year = {2021},
    issn = {0893-6080},
    doi = {https://doi.org/10.1016/j.neunet.2021.03.004},
    url = {https://www.sciencedirect.com/science/article/pii/S0893608021000848},
    author = {Zhongxin Bai and Xiao-Lei Zhang},
    keywords = {Speaker recognition, Speaker verification, Speaker identification, Speaker diarization, Robust speaker recognition, Deep learning},
    abstract = {Speaker recognition is a task of identifying persons from their voices. Recently, deep learning has dramatically revolutionized speaker recognition. However, there is lack of comprehensive reviews on the exciting progress. In this paper, we revie several major subtasks of speaker recognition, including speaker verification, identification, diarization, and robust speaker recognition, with a focus on deep-learning-based methods. Because the major advantage of deep learning over conventional methods is its representation ability, which is able to produce highly abstract embedding features from utterances, we first pay close attention to deep-learning-based speaker feature extraction, including the inputs, network structures, temporal pooling strategies, and objective functions respectively, which are the fundamental components of many speaker recognition subtasks. Then, we make an overview of speaker diarization, with an emphasis of recent supervised, end-to-end, and online diarization. Finally, we survey robust speaker recognition from the perspectives of domain adaptation and speech enhancement, which are two major approaches of dealing with domain mismatch and noise problems. Popular and recently released corpora are listed at the end of the paper.}
}

@article {kin2010,
    title = {An overview of text-independent speaker recognition: From features to supervectors},
    journal = {Speech Communication},
    volume = {52},
    number = {1},
    pages = {12-40},
    year = {2010},
    issn = {0167-6393},
    doi = {https://doi.org/10.1016/j.specom.2009.08.009},
    url = {https://www.sciencedirect.com/science/article/pii/S0167639309001289},
    author = {Tomi Kinnunen and Haizhou Li},
    keywords = {Speaker recognition, Text-independence, Feature extraction, Statistical models, Discriminative models, Supervectors, Intersession variability compensation},
    abstract = {This paper gives an overview of automatic speaker recognition technology, with an emphasis on text-independent recognition. Speaker recognition has been studied actively for several decades. We give an overview of both the classical and the state-of-the-art methods. We start with the fundamentals of automatic speaker recognition, concerning feature extraction and speaker modeling. We elaborate advanced computational techniques to address robustness and session variability. The recent progress from vectors towards supervectors opens up a new area of exploration and represents a technology trend. We also provide an overview of this recent development and discuss the evaluation methodology of speaker recognition systems. We conclude the paper with discussion on future directions.}
}

@inproceedings {deep2018,
    author={Snyder, David and Garcia-Romero, Daniel and Sell, Gregory and Povey, Daniel and Khudanpur, Sanjeev},
    booktitle={2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
    title={X-Vectors: Robust DNN Embeddings for Speaker Recognition}, 
    year={2018},
    volume={},
    number={},
    pages={5329-5333},
    doi={10.1109/ICASSP.2018.8461375}
}

@article {korea_vishing,
    author = {Song, Jaeseung and Kim, Hyoungshick and Gkelias, Athanasios},
    title = {iVisher: Real-Time Detection of Caller ID Spoofing},
    journal = {ETRI Journal},
    volume = {36},
    number = {5},
    pages = {865-875},
    keywords = {Voice over IP, security, caller ID concealment, SIP},
    doi = {https://doi.org/10.4218/etrij.14.0113.0798},
    url = {https://onlinelibrary.wiley.com/doi/abs/10.4218/etrij.14.0113.0798},
    eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.4218/etrij.14.0113.0798},
    abstract = {Voice phishing (vishing) uses social engineering, based on people's trust in telephone services, to trick people into divulging financial data or transferring money to a scammer. In a vishing attack, a scammer often modifies the telephone number that appears on the victim's phone to mislead the victim into believing that the phone call is coming from a trusted source, since people typically judge a caller's legitimacy by the displayed phone number. We propose a system named iVisher for detecting a concealed incoming number (that is, caller ID) in Session Initiation Protocol–based Voice-over-Internet Protocol initiated phone calls. Our results demonstrate that iVisher is capable of detecting a concealed caller ID without significantly impacting upon the overall call setup time.},
    year = {2014}
}

@article {sr_survey,
    author = {Kabir, Muhammad Mohsin and Mridha, M. F. and Shin, Jungpil and Jahan, Israt and Ohi, Abu Quwsar},
    journal={IEEE Access},
    title={A Survey of Speaker Recognition: Fundamental Theories, Recognition Methods and Opportunities},
    year={2021},
    volume={9},
    number={},
    pages={79236-79263},
    doi={10.1109/ACCESS.2021.3084299}
}

@article {irum_overview,
    author = {Amna Irum and Ahmad Salman},
    title = {Speaker Verification Using Deep Neural Networks: A Review},
    journal = {International Journal of Machine Learning and Computing},
    year = {2019},
    volume = {9},
    number = {1},
    pages = {20-25},
    doi = {10.18178/IJMLC}
}

@inproceedings {eshan_deep,  author={Variani, Ehsan and Lei, Xin and McDermott, Erik and Moreno, Ignacio Lopez and Gonzalez-Dominguez, Javier},  booktitle={2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},   title={Deep neural networks for small footprint text-dependent speaker verification},   year={2014},  volume={},  number={},  pages={4052-4056},  doi={10.1109/ICASSP.2014.6854363}}

@inproceedings {deep_text_dep,  author={Dey, Subhadeep and Koshinaka, Takafumi and Motlicek, Petr and Madikeri, Srikanth},  booktitle={2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},   title={DNN Based Speaker Embedding Using Content Information for Text-Dependent Speaker Verification},   year={2018},  volume={},  number={},  pages={5344-5348},  doi={10.1109/ICASSP.2018.8461389}}

@incollection{york_vishing,
title = {CHAPTER 6 - Identity, Spoofing, and Vishing},
editor = {Dan York},
booktitle = {Seven Deadliest Unified Communications Attacks},
publisher = {Syngress},
address = {Boston},
pages = {117-136},
year = {2010},
isbn = {978-1-59749-547-9},
doi = {https://doi.org/10.1016/B978-1-59749-547-9.00006-5},
url = {https://www.sciencedirect.com/science/article/pii/B9781597495479000065},
author = {Dan York},
abstract = {Publisher Summary
The identity in the world of VoIP and unified communications (UC) is just a text string that can be easily modified or replaced. Most UC systems will simply pass along the caller ID they receive from the sending endpoint. The attacker can therefore set up his or her external attack system or endpoints and give them internal caller ID information. The target receiving the call would see what appears to be an internal caller ID, even though the call may be originating outside the network. One of the simplest ways to modify an identity in a UC system is to change the display name or other identity information within the endpoint itself. There is nothing that prevents an attacker from setting up one's own VoIP or UC system complete with whatever endpoints the attacker wants to use. An attacker could download a free, open-source platform such as Asterisk, set it up on a very basic computer system, connect it to the Internet, and start making calls as someone else. Within Asterisk, Session Initiation Protocol (SIP) endpoint configuration takes place within the “sip.conf” configuration file.}
}

@incollection{fishing_book,
title = {Chapter 6 - Phishing, SMishing, and Vishing},
editor = {Ken Dunham},
booktitle = {Mobile Malware Attacks and Defense},
publisher = {Syngress},
address = {Boston},
pages = {125-196},
year = {2009},
isbn = {978-1-59749-298-0},
doi = {https://doi.org/10.1016/B978-1-59749-298-0.00006-9},
url = {https://www.sciencedirect.com/science/article/pii/B9781597492980000069},
abstract = {Publisher Summary
Phishing attacks appear in different forms other than forged emails and spoofed Web sites. They can exploit vulnerabilities in open wireless access points, Bluetooth, and handheld devices. Further, such attacks can be carried out using SMS or VoIP. In a mobile environment, such attacks are easier to set up and more convincing than traditional mass mailing techniques. Although traditional phishing attacks rely on fooling the recipient, in a mobile environment, the attack can take advantage of the limited (or lack of) security in mobile devices. Several ubiquitous solutions available for desktop and wired computers are generally not as readily available across wireless and mobile devices. This is due to the limitations in mobile devices, namely power, processing, and storage. Implementing traditional antiphishing solutions, such as machine learning approaches, in a mobile environment is inapplicable since some of these solutions are heavy in nature. Antiphishing solutions in a mobile environment should take advantage of the high predictive accuracy of machine learning approaches and at the same time conceal the high overhead associated with such approaches by building a distributed client-server framework to thwart the attacks.}
}

@article{hindi_gmm,
title = {Speaker Recognition for Hindi Speech Signal using MFCC-GMM Approach},
journal = {Procedia Computer Science},
volume = {125},
pages = {880-887},
year = {2018},
note = {The 6th International Conference on Smart Computing and Communications},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2017.12.112},
url = {https://www.sciencedirect.com/science/article/pii/S1877050917328806},
author = {Ankur Maurya and Divya Kumar and R.K. Agarwal},
keywords = {Identification rate (IR), MFCC-GMM, MFCC-VQ},
}

@article{jin_noise_mfcc,
title = {Evaluation and modeling of automotive transmission whine noise quality based on MFCC and CNN},
journal = {Applied Acoustics},
volume = {172},
pages = {107562},
year = {2021},
issn = {0003-682X},
doi = {https://doi.org/10.1016/j.apacoust.2020.107562},
url = {https://www.sciencedirect.com/science/article/pii/S0003682X20306666},
author = {Shuaipu Jin and Xiufeng Wang and Leilei Du and Dan He},
keywords = {Automotive transmission, Subjective evaluation, Sound quality, MFCC-CNN, Nonstationary vehicle noise},
abstract = {The sound quality of automotive transmission noise strongly influences passengers’ psychological and physiological perceptions. To predict the sound quality of automotive transmission noise, a uniform deceleration noise test with two automotive transmissions has been conducted in a semi-anechoic room. All recorded transmission noise signals have been divided into 5 s segments and subsequently evaluated subjectively through the rating scales test by a jury. In addition, a novel prediction method, namely, Mel-Frequency Cepstral Coefficients-based convolutional neural networks (MFCC-CNN), which substitute the softmax classification layer for the linear transform prediction layer at the output of the general CNN’s structure and take MFCC feature map as input, has been proposed to predict the transmission sound quality. MFCC's distinguishing performance on sound quality has been validated. The parameter selection of the MFCC-CNN model has been compared and studied using a grid search. In addition, three conventional machine-learning-based methods have been introduced to enable a comparison of the performance with the newly developed MFCC-CNN. The results show the following: (1) In different transmission gears, MFCC features can distinguish different sound quality noises. (2) The accuracy of the proposed MFCC-CNN sound quality prediction approach are better than those of the 3 other referenced methods. (3) The correlation coefficient of prediction value from MFCC-CNN is more than 0.95 and the mean absolute error of prediction value from MFCC-CNN is less than 0.55, which fully meets the need of engineering. Finally, the newly proposed MFCC-CNN approach may be extended to address other vehicle noises in the future.}}

@article{gmm_ubm_smartphone,
title = {Frequency features and GMM-UBM approach for gait-based person identification using smartphone inertial signals},
journal = {Pattern Recognition Letters},
volume = {73},
pages = {60-67},
year = {2016},
issn = {0167-8655},
doi = {https://doi.org/10.1016/j.patrec.2016.01.008},
url = {https://www.sciencedirect.com/science/article/pii/S0167865516000209},
author = {Rubén San-Segundo and Ricardo Cordoba and Javier Ferreiros and Luis Fernando D'Haro-Enríquez},
keywords = {Feature extraction, GMM-UBM, Person identification, Gait recognition, Smartphone inertial signals},
abstract = {This paper describes the development of a Gait-based Person Identification (GPI) system based on a Gaussian Mixture Model-Universal Background Model (GMM-UBM) approach that uses inertial signals from a smartphone. The system integrates five main modules or steps: signal pre-processing, feature extraction, GMM-UBM training, Maximum A Posteriori (MAP) adaptation, and a comparison module for providing the identified user. This system also integrates new feature extraction strategies proposed recently (Mel Frequency Cepstral Coefficients (MFCCs) and Perceptual Lineal Prediction (PLP) coefficients) for improving the results. This study has been done using the public available dataset called UCI Human Activity Recognition Using Smartphones dataset. A six-fold cross-validation procedure has been carried out, showing the average value for every experiment. The final results demonstrate the capability of the GMM-UBM approach for gait recognition, and show how the PLP coefficients can improve system performance while reducing drastically the number of features (from 561 to 90). The best result shows a User Recognition Error Rate of 34.0\% with 30 enrolled users. When reducing the number of enrolled users, the error rate decreases: for a number smaller than six, the URER error becomes lower than 10\%.}
}

@article{gmm_ubm_hindi,
title = {Significance of GMM-UBM based Modelling for Indian Language Identification},
journal = {Procedia Computer Science},
volume = {54},
pages = {231-236},
year = {2015},
note = {Eleventh International Conference on Communication Networks, ICCN 2015, August 21-23, 2015, Bangalore, India Eleventh International Conference on Data Mining and Warehousing, ICDMW 2015, August 21-23, 2015, Bangalore, India Eleventh International Conference on Image and Signal Processing, ICISP 2015, August 21-23, 2015, Bangalore, India},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2015.06.027},
url = {https://www.sciencedirect.com/science/article/pii/S1877050915013514},
author = {V. Ravi Kumar and Hari Krishna Vydana and Anil Kumar Vuppala},
keywords = {Language identification, Phonotactics, Spectral features, Gaussian mixture modelling (GMM), Universal background model (UBM).},
abstract = {Most of the Indian languages are originated from Devanagari, the script of the Sanskrit language. In-spite of similarity in phoneme sets, every language its own influence on the phonotactic constraints of speech in that language. A modelling technique that is capable of capturing the slightest variations imparted by the language is a pre-requisite for developing a language identification system (LID). Use of Gaussian mixture modelling technique with a large number of mixture components demands a large training data for each language class, which is hard to collect and handle. In this work, phonotactic variations imparted by the different languages are modelled using Gaussian mixture modelling with a universal background model (GMM-UBM) technique. In GMM-UBM based modelling certain amount of data from all the language classes is pooled to develop a universal background model (UBM) and the model is adapted to each class. Spectral features (MFCC) are employed to represent the language specific phonotactic information of speech in different languages. During the present study, LID systems are developed using the speech samples from IITKGP-MLILSC. In this work, performance of the proposed GMM-UBM based LID system is compared with conventional GMM based LID system. An average improvement of 7–8\% is observed due to the use of UBM-based modelling of developing a LID system.}
}

@article{em_new,
title = {A new EM algorithm for flexibly tied GMMs with large number of components},
journal = {Pattern Recognition},
volume = {114},
pages = {107836},
year = {2021},
issn = {0031-3203},
doi = {https://doi.org/10.1016/j.patcog.2021.107836},
url = {https://www.sciencedirect.com/science/article/pii/S0031320321000236},
author = {Hadi Asheri and Reshad Hosseini and Babak Nadjar Araabi},
keywords = {Gaussian mixture model, Parameter sharing, Tied GMM, Computation factorization and reduction, Newton method, Fast minimal residual method, Clustering},
abstract = {Gaussian mixture models (GMMs) are a family of generative models used extensively in many machine learning applications. The modeling power of GMMs is directly linked to the number of components. Memory, computational load and lack of enough data hinders using GMMs with large number of components. To tackle this problem, GMMs with a tying scheme that we call flexibly tied GMM was proposed in the literature of the speech recognition community. In the literature, a coordinate-descent EM algorithm was proposed for estimating the parameters of flexibly tied GMMs. In this paper, we aim at reintroducing flexibly tied GMMs to the pattern recognition community. We rigorously investigate various optimization methods and see none of the out-of-the-box optimization methods can solve the parameter estimation problem due to the complexity of the cost function. To this end, we develop a fast Newton EM algorithm that combined with the coordinate descent EM algorithm, it significantly outperforms pure coordinate descent EM and all other optimization algorithms. Furthermore, we propose a computation factorization technique to increase the speed and decrease memory requirement of both Newton and coordinate descent EM algorithms in the case of large number of components. Experimental results on many datasets verifies the efficacy of the proposed algorithm. It also verifies that flexibly tied GMM outperforms both basic GMM and other types of tied GMMs on the datasets in terms of the log-likelihood. We also evaluate the performance of flexibly tied GMM on a clustering problem, and show that it can outperform basic GMM and kmeans algorithm.}
}

@article{vr_ml,
title = {Voice recognition system using machine learning techniques},
journal = {Materials Today: Proceedings},
year = {2021},
issn = {2214-7853},
doi = {https://doi.org/10.1016/j.matpr.2021.04.075},
url = {https://www.sciencedirect.com/science/article/pii/S221478532102931X},
author = {Ashraf {Tahseen Ali} and Hasanen S. Abdullah and Mohammad N. Fadhil},
keywords = {Machine learning, Voice recognition, Naïve Bayes, k-Nearest Neighbor, MFCC},
abstract = {Voice is a Special metric that, in addition to being natural to users, offers similar, if not higher, levels of security when compared to some traditional biometrics systems. The aim of this paper is to detect impostors using various machine learning techniques to see which combination works best for speaker recognition and classification. We present several methods of audio preprocessing, such as noise reduction and vocal enhancements, to improve the audios available in real environments. Mel Frequency Cepstral Coefficients (MFCC) are extracted for each audio, along with their differentials and accelerations, to verify machine learning classification methods such as PART, JRip, Nave Bayes, RT, J48, Random Forest, and k-Nearest Neighbor Classifiers. examine the 7 classifiers on two datasets, the extent of accuracy achieved for each classifier. Among the high performance were the random forest algorithm and the naive bias algorithm, and the weak performance of the PART algorithm.}
}

@article{gr_unc_env,
title = {Voice gender recognition under unconstrained environments using self-attention},
journal = {Applied Acoustics},
volume = {175},
pages = {107823},
year = {2021},
issn = {0003-682X},
doi = {https://doi.org/10.1016/j.apacoust.2020.107823},
url = {https://www.sciencedirect.com/science/article/pii/S0003682X20309282},
author = {Mohammed M. Nasef and Amr M. Sauber and Mohammed M. Nabil},
keywords = {Voice gender recognition, Self-attention, MFCC, Logistic regression, Inception},
abstract = {Voice Gender Recognition is a non-trivial task that is extensively studied in the literature, however, when the voice gets surrounded by noises and unconstrained environments, the task becomes more challenging. This paper presents two Self-Attention-based models to deliver an end-to-end voice gender recognition system under unconstrained environments. The first model consists of a stack of six self-attention layers and a dense layer. The second model adds a set of convolution layers and six inception-residual blocks to the first model before the self-attention layers. These models depend on Mel-frequency cepstral coefficients (MFCC) as a representation of the audio data, and Logistic Regression for classification. The experiments were done under unconstrained environments such as background noise and different languages, accents, ages and emotional states of the speakers. The results demonstrate that the proposed models were able to achieve an accuracy of 95.11\%, 96.23\%, respectively. These models achieved superior performance in all criteria and are believed to be state-of-the-art for Voice Gender Recognition under unconstrained environments.}
}

@article{forensic_gmm_ubm_mfcc,
title = {Forensic Gender Speaker Recognition under Clean and Noisy Environments},
journal = {Procedia Computer Science},
volume = {151},
pages = {897-902},
year = {2019},
note = {The 10th International Conference on Ambient Systems, Networks and Technologies (ANT 2019) / The 2nd International Conference on Emerging Data and Industry 4.0 (EDI40 2019) / Affiliated Workshops},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2019.04.124},
url = {https://www.sciencedirect.com/science/article/pii/S1877050919305885},
author = {Ouassila KENAI and Salim DJEGHIOUR and Nassim ASBAI and Mhania GUERTI},
keywords = {Forensic Gender Speaker Recognition (FGSR),  model, Likelihood Ratio (), clean and noisy conditions},
abstract = {The Forensic Gender Speaker Recognition (FGSR) deals with finding out the gender of a person from his or her voice. This task has been implemented in several Automatic Speaker Recognition systems and has proved to be of great significance. The use of gender recognition eases for user authentication and identification in high security systems. In this paper, we have used the gender recognition for speakers using Mel Frequency Cepstral Coefficients (MFCCs), a Gaussian Mixture Model-Universal Background Model (GMM-UBM) and Likelihood Report (LR) were used for modelization of features extracted from the speech signal of speakers under clean and noisy conditions. The performance of FGSR system is evaluated in terms of Equal Proportion Probability (EPP). Three sets of experiments were performed - the first experiment; corpus contains males’ voices. The second; contains females’ voices and third; contains both voices of both sexes. In clean conditions, the average accuracy of the first experiment was slightly higher for EPP=3.1579\% than the second and the third experiments. Therefore, Performance evaluation results are encouraging in clean conditions compared to in noisy condition for EPP=27\%.}
}

@article{lstm,
title = {An effective gender recognition approach using voice data via deeper LSTM networks},
journal = {Applied Acoustics},
volume = {156},
pages = {351-358},
year = {2019},
issn = {0003-682X},
doi = {https://doi.org/10.1016/j.apacoust.2019.07.033},
url = {https://www.sciencedirect.com/science/article/pii/S0003682X19304281},
author = {Fatih Ertam},
keywords = {Gender recognition, Gender classification, Deep learning, Deeper LSTM, Machine learning},
abstract = {It is not difficult to estimate the gender of the human from other people's audio files. In general, people can easily identify the gender of the owner of a conversation with the experience they have acquired. However, it is not easy to predict whether a person is a man or a woman by computer systems. Hence, many papers and proposals have been presented to solve this problem using computer systems. In this study, Deeper Long Short Term Memory (LSTM) Networks structure was used for the prediction of gender from an audio data set. The study was successful at predicting gender with an accuracy of 98.4\%. The proposed approach consists of 3 main steps. Firstly, 10 most effective data attributes were selected (i). Then, a deep learning-based network was created with the double-layer LSTM structure (ii). In addition to the performance comparison of the classification, accuracy values, sensitivity, and specificity performance metrics were also calculated (iii). At the same time, the accuracy of the proposed method was compared with the accuracy values obtained from the classifiers generated by conventional machine learning approaches. The study was successful at predicting gender with 98.4\% success rate. It is thought that the study will be a pioneer in this field as an effective and fast approach for gender recognition.}
}
